{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [프로젝트3] 고객 상담 문의 유형 분류를 위해 RNN 기반 모델 적용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BG_0zjG13zZy"
   },
   "source": [
    "\n",
    "## 프로젝트 목표\n",
    "---\n",
    "- 딥러닝 모델에서 처리 가능하도록 데이터 전처리\n",
    "- RNN 기반 모델 중 하나인 LSTM을 딥러닝 프레임워크로 구성\n",
    "- LSTM을 통하여 문의 유형 분류 모델 학습 및 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS7RvUWi5vJe"
   },
   "source": [
    "## 프로젝트 목차\n",
    "---\n",
    "\n",
    "1. **데이터 전처리:** 프로젝트 1에서 가져온 데이터를 딥러닝 프레임워크에서 쓸 수 있게 전처리합니다.\n",
    "\n",
    "2. **LSTM 모델 구성:** RNN 기반 모델 중 하나인 LSTM을 torch 기반으로 구성합니다.\n",
    "\n",
    "3. **LSTM을 통한 문의 유형 분류 문제:** LSTM을 통하여 문의 유형 분류 문제를 해결할 수 있도록 LSTM을 학습 및 평가합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-rxhtJI5_D2"
   },
   "source": [
    "## 프로젝트 개요\n",
    "---\n",
    "\n",
    "프로젝트 1에서 불러오고 자연어 전처리한 데이터를 바탕으로 본격적으로 분류 문제를 딥러닝 모델로 해결해 보고자 합니다.\n",
    "\n",
    "이를 위하여 데이터를 딥러닝 모델의 입력값이 될 수 있도록 전처리를 하고, 딥러닝 모델 중 하나인 LSTM을 `Pytorch` 기반으로 구성합니다.\n",
    "\n",
    "구성한 모델을 고객 상담 기록 데이터로 학습하여 문의 유형 분류 문제를 풀 수 있도록 LSTM을 학습 및 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1. 라이브러리 및 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로젝트 1에서 사용한 데이터와 모델 학습을 위해 필요한 라이브러리를 불러옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.9.0)\n",
      "Collecting torchtext==0.11.0\n",
      "  Downloading torchtext-0.11.0-cp38-cp38-manylinux1_x86_64.whl (8.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0 MB 20.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torchtext==0.11.0) (4.55.0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.0-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |███████████▌                    | 315.9 MB 125.2 MB/s eta 0:00:05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |█████████████████████████       | 691.1 MB 118.2 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 881.9 MB 2.5 kB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchtext==0.11.0) (2.25.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchtext==0.11.0) (1.19.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchtext==0.11.0) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchtext==0.11.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->torchtext==0.11.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchtext==0.11.0) (2020.12.5)\n",
      "Installing collected packages: torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0\n",
      "    Uninstalling torch-1.9.0:\n",
      "      Successfully uninstalled torch-1.9.0\n",
      "Successfully installed torch-1.10.0 torchtext-0.11.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchtext==0.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./01_data.csv', encoding='cp949')\n",
    "texts = data['메모'].tolist() # 자연어 데이터를 리스트 형식으로 변환합니다\n",
    "label_list = data['상담유형3_GT'].unique().tolist()\n",
    "labels = data['상담유형3_GT'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    # 정제: 한글, 공백 제외한 문자 제거\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_clean = []\n",
    "for i in range(len(texts)):\n",
    "    text_clean = cleaning(texts[i])\n",
    "    texts_clean.append(text_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터와 테스트 데이터를 구분합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8*len(texts_clean))\n",
    "\n",
    "texts_labels = list(zip(texts_clean,labels))\n",
    "random.shuffle(texts_labels)\n",
    "texts_clean, labels = zip(*texts_labels)\n",
    "\n",
    "train_texts = texts_clean[:num_train]\n",
    "train_labels = labels[:num_train]\n",
    "\n",
    "test_texts = texts_clean[num_train:]\n",
    "test_labels = labels[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({'text': train_texts,\n",
    "                          'label': train_labels})\n",
    "test_data = pd.DataFrame({'text': test_texts,\n",
    "                          'label': test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('./train_data.csv',index=False)\n",
    "test_data.to_csv('./test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 데이터 전처리\n",
    "---\n",
    "\n",
    "List 형태로 저장되어 있는 데이터와 라벨을 torch 모델에 적용할 수 있도록 전처리합니다. 이때, torchtext 라이브러리를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Okt()\n",
    "\n",
    "TEXT = torchtext.legacy.data.Field(tokenize=tokenizer.morphs,\n",
    "                 include_lengths=True)\n",
    "\n",
    "LABEL = torchtext.legacy.data.LabelField(dtype=torch.long)\n",
    "\n",
    "fields = {'text': ('text', TEXT), 'label': ('label', LABEL)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, validation, test 데이터를 구분지어 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = torchtext.legacy.data.TabularDataset.splits(\n",
    "                            path = './',\n",
    "                            train = 'train_data.csv',\n",
    "                            test = 'test_data.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연어 데이터를 컴퓨터로 표현하기 위한 임베딩 벡터를 가져옵니다. 본 프로젝트에서는 한국어 임베딩이 있는 FastText 서브 워드 임베딩을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/wiki.simple.vec: 293MB [00:40, 7.18MB/s]                               \n",
      "  0%|          | 0/111051 [00:00<?, ?it/s]Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|██████████| 111051/111051 [00:08<00:00, 13212.93it/s]\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data,\n",
    "                 max_size = 10000,\n",
    "                 vectors = 'fasttext.simple.300d',\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = batch_size,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  73,  130,  182,  400,   10,  122,   10,  125,  130,  122,   11,  800,\n",
       "          4092,  829,   11,  136,   89,   11,   66,  125,  403,  163, 1041,   11,\n",
       "           179,  627,   57, 2295,  237,  436,  123,  479,  459,   41,  108,   94,\n",
       "           281,  400,   36,   73,  415,   73,   73,  106,  146,   10,   11,   11,\n",
       "          1011,   80,   11,   94,  400, 1823,  229,   41,  321,   10,  181,  788,\n",
       "            73,   94,   41,  305],\n",
       "         [  62, 1205,  690,  178,  111,  348,   13,   51, 1205,   51,   98,   88,\n",
       "           119,  124,   98,  172, 1325,   98,   65,   56,  469,   11,   48,   98,\n",
       "           270,   17,   76, 3925,  386,   95,  163,  232,  207,   30,   13,   79,\n",
       "            50,  179,   73,  491,   10,  491,  491,   17, 1010,   27,   42,   98,\n",
       "          3441,   56,  148,   79,   43,  109,   22,  193,   72,  119,   27,   43,\n",
       "           491,   79,   17,  367],\n",
       "         [ 203,   51,  875,   26,   13,  120,   11,  511, 3455,   32,   56,  216,\n",
       "           120,   22,   95,  168, 1951,  227,   59,   42,   17,   50,  141,   95,\n",
       "           465,   32,  186,  168,    3,  124,   11,   97,  707,  151,  278,  275,\n",
       "           294,  275,  464,  464,    6,  464,  464,   32,  796,   63,   98,  517,\n",
       "            11,   42,   97,  275,   84,   90,  211,   17,   44,   22, 4478,   74,\n",
       "           464,  275,  106,   54],\n",
       "         [ 895,  110,  649,   83,   11,   98,  114,  616,   94,   95,   10,   51,\n",
       "            98,  905,  326,   98,  161,  148,  188,   45,  308,   97,   88,  390,\n",
       "            11,   56,  250,  120,   17,    9,   95,   42,  556,   22,   17,  264,\n",
       "           608,  264,  613,   63,  710,    6,   35,   97,  122,   49,   56,  571,\n",
       "          4625,   45,   13,  264,  538,  192,  302,   22,   11,   35,   33,  332,\n",
       "          1357,  264,  227, 2070],\n",
       "         [  73,  188,   11,   22,  143,    6,   97,   26,  252,   10,   13,  585,\n",
       "            95,   54,   11, 3711,    6,  537,   10,   52,  324,  229,  167,   88,\n",
       "           144,  133,   40, 2374,   32,   63,   22,   45,  546,  129,  291,   89,\n",
       "            73,  587,   47,   95,   72,  626,  284, 3942,   51,   26,  326,  221,\n",
       "            10,    7,   25,   89,   52,   22,   59,  795,   97,  129,  922, 4314,\n",
       "           107,   89,   22,   24],\n",
       "         [  25,   32,   56,  357,   97,   52,   11, 2705,  956,   13,   11, 1677,\n",
       "           109, 1387,   88,   64,    2,  483,   49,  102,   53,    7,  129,  212,\n",
       "            42,  308,   62,  708,  441,   70,    9,  326,  173,  267,   32,    2,\n",
       "            50,    3,  626,   35,  130, 1026,  129,  212,  125, 1444,   11,  326,\n",
       "            13,   52,  112,   40,   67,   27,   47,    8, 2509,    3,  790,    3,\n",
       "            27,  495,  133, 1092],\n",
       "         [ 284,   56,   11,    2,  229,   83,  212,   18,   11,   51,  456, 4097,\n",
       "           220,  180,  212,  229,    9,   63,  412,  652,  133,   11,   22,    9,\n",
       "            45, 3941,  329,  121,   12,    3,   13,   11,  167,  291,  300,    9,\n",
       "           534,   71, 1026,    2,  332,   26,   22,   51,   56,    3,  180,   11,\n",
       "            13,  134,    2,   53,   42,  192,   27,    3,   14,    9, 1361,  142,\n",
       "           827,  535,   14,  163],\n",
       "         [ 129,  346,  212,    9,  167,   76,   13,   35,  144,  125,  134,  284,\n",
       "          1193,  361,    9, 1510,   83,  319,   78,   93,   17,  134,   80,   25,\n",
       "           141,  370,   83,   11,   26,    9,    2,   52,  129,    9,  364, 1836,\n",
       "           307,  113,    3,   17,  113,  113,   17,  192,  133,   40,   13, 1396,\n",
       "            25,  133,   30,   22,   45,  535,    3,   30, 1006,   30,   22,  113,\n",
       "             3,    3,   13, 2471],\n",
       "         [  22,  120,  134,   40,   52,    3,   63,   17,    2,  133,   13,  733,\n",
       "          1963,  178,   25,    9,   40,  175,   11,   70,   80,   13,    3,    3,\n",
       "          2485,    3,   22,   13,   22,   30,   30,   67,   22,   30,   18,  113,\n",
       "            64,  333,   30,   80,  333,  333,   80,  388,    3,  105,   30, 4843,\n",
       "             2,  105,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1],\n",
       "         [   3,  366,   13,  105,  102,   99,   30,   80,   49,    3,   30,   22,\n",
       "            30,   28,    3,   13,  105,   30,   78,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1]]),\n",
       " tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "          9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  8,  8,  8,  8,\n",
       "          8,  8,  8,  8,  8,  8,  8,  8,  8,  8]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator)).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['발수신불가', '통품상담성', '기업형메시지(금융권인증SMS)', '초기접속불가', '속도저하', '호단절', '단문메세지(SMS)', '이설요청/철거요청', '기타 Application', '데이터 사용중 끊김', '음질불량', 'T제공 어플', 'MMS', '수신불가', '3G천이', '발신불가', '카카오', '통화중대기'] 18\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.itos, len(LABEL.vocab.stoi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM 모델 구성\n",
    "\n",
    "---\n",
    "\n",
    "LSTM 분류 모델을 torch로 구성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, pad_idx):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 단어 임베딩\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # 분류자 (classifier)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, text, text_length):\n",
    "        embeds = self.word_embeddings(text)\n",
    "        packed_embeds = nn.utils.rnn.pack_padded_sequence(embeds, text_length)\n",
    "        _, (hidden, cell) = self.lstm(packed_embeds)\n",
    "        logits = self.fc(hidden.squeeze(0))\n",
    "        scores = F.log_softmax(logits, dim=1)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM을 통한 문의 유형 분류 문제\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 하이퍼파라미터 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab) # 단어 개수\n",
    "EMBEDDING_DIM = 300 # 임베딩 차원\n",
    "HIDDEN_DIM = 256 # 은닉 상태 차원\n",
    "TARGET_SIZE = len(LABEL.vocab.stoi) # 라벨 클래스 개수\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # 패딩 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델, 손실 함수 (loss function), 옵티마이저 (optimizer) 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TARGET_SIZE, PAD_IDX)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩을 사전 학습된 FastText 임베딩으로 덮어씌웁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4905, -1.5179, -0.0916,  ...,  1.5286,  0.2033, -0.4287],\n",
       "        [-0.7065,  0.2575, -0.9770,  ..., -0.9159,  0.1888,  1.1423],\n",
       "        [ 0.8592, -0.7363,  0.4632,  ..., -0.6997,  1.6823, -0.6281],\n",
       "        ...,\n",
       "        [-0.0139, -2.4191,  1.7068,  ...,  1.1082,  0.2201, -1.2869],\n",
       "        [ 1.2630,  0.4783,  0.7196,  ...,  1.5432,  1.5518,  0.8923],\n",
       "        [-1.3336,  2.5820,  0.6197,  ..., -0.2017,  0.9644, -0.0027]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.word_embeddings.weight.data.copy_(pretrained_embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전에 정의되지 않은 단어에 대한 토큰인 `<UNK>`와 빈 칸을 위한 토큰인 `<PAD>`를 0 벡터로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.8592, -0.7363,  0.4632,  ..., -0.6997,  1.6823, -0.6281],\n",
      "        ...,\n",
      "        [-0.0139, -2.4191,  1.7068,  ...,  1.1082,  0.2201, -1.2869],\n",
      "        [ 1.2630,  0.4783,  0.7196,  ...,  1.5432,  1.5518,  0.8923],\n",
      "        [-1.3336,  2.5820,  0.6197,  ..., -0.2017,  0.9644, -0.0027]])\n"
     ]
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "print(UNK_IDX, PAD_IDX)\n",
    "\n",
    "model.word_embeddings.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.word_embeddings.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.word_embeddings.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] 모델 성능 평가를 위하여 정확도를 예측하는 함수를 작성해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction, label):\n",
    "    '''\n",
    "    input\n",
    "    prediction: 배치에 대하여 각 클래스 별 log-softmax 값, shape (batch_size, num_classes)\n",
    "    label: 배치에 대하여 클래스 라벨, shape (batch_size,)\n",
    "    '''\n",
    "    prediction_argmax = prediction.max(dim=-1)[1] # prediction 값을 통하여 데이터 별 예측 클래스 추출\n",
    "    correct = (prediction_argmax == label).float() # 각 데이터 별로 예측 값이 실제 라벨을 맞췄는지 확인\n",
    "    acc = correct.sum() / len(correct) # 배치에 대한 정확도\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, loss_function):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, text_length = batch.text\n",
    "        if 0. in text_length:\n",
    "            continue\n",
    "        predictions = model(text, text_length)\n",
    "        \n",
    "        loss = loss_function(predictions, batch.label)\n",
    "        acc = accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [TODO] 위의 train 함수를 참고하여 모델을 평가하는 함수를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, loss_function):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_length = batch.text # batch에서 텍스트와 텍스트 길이 구분\n",
    "            if 0. in text_length:\n",
    "                continue\n",
    "            predictions = model(text, text_length) # LSTM 모델에 데이터 주입 \n",
    "            \n",
    "            loss = loss_function(predictions, batch.label) # 로스 계산\n",
    "            acc = accuracy(predictions, batch.label) # 정확도 계산\n",
    "            \n",
    "            epoch_loss += loss.item() # 전체 로스 계산을 위한 저장\n",
    "            epoch_acc += acc.item() # 전체 정확도 계산을 위한 저장\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 2.510 | Train Acc: 21.37%\n",
      "\t Val. Loss: 2.147 |  Val. Acc: 25.55%\n",
      "Epoch: 02\n",
      "\tTrain Loss: 1.919 | Train Acc: 35.65%\n",
      "\t Val. Loss: 1.862 |  Val. Acc: 35.58%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 1.611 | Train Acc: 45.76%\n",
      "\t Val. Loss: 1.709 |  Val. Acc: 40.90%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 1.330 | Train Acc: 54.26%\n",
      "\t Val. Loss: 1.552 |  Val. Acc: 45.89%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 1.069 | Train Acc: 62.83%\n",
      "\t Val. Loss: 1.454 |  Val. Acc: 49.62%\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.891 | Train Acc: 69.16%\n",
      "\t Val. Loss: 1.524 |  Val. Acc: 49.04%\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.734 | Train Acc: 74.38%\n",
      "\t Val. Loss: 1.406 |  Val. Acc: 53.02%\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.561 | Train Acc: 80.10%\n",
      "\t Val. Loss: 1.476 |  Val. Acc: 49.29%\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.439 | Train Acc: 84.73%\n",
      "\t Val. Loss: 1.359 |  Val. Acc: 58.47%\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.319 | Train Acc: 89.35%\n",
      "\t Val. Loss: 1.352 |  Val. Acc: 59.54%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_function)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_function)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'lstm-best.pt')\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터에 대하여 평가를 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.380 | Test Acc: 57.91%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('lstm-best.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_function)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
